# SlackIQ

This project summarizes Slack threads using an LLM (like Mistral) via Ollama, stores the summaries in a CSV file, and uses those summaries to answer questions using another LLM (like LLaMA3). The entire setup runs locally using Flask.

Components
1. Slack Setup
2. Ollama Installation
3. Flask App APIs
     /get_thread_messages
     /summarize_thread
     /ask_question




